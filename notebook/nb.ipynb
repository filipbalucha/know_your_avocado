{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python37464bit6780e0a3df2b47e690b752b8e1a7a39c",
   "display_name": "Python 3.7.4 64-bit",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms\n",
    "# from torchvision.transforms import ToTensor, Resize, Compose, ToPILImage\n",
    "from torchvision.utils import make_grid\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "#from torchvision.datasets import CIFAR10\n",
    "import torchvision.models as models\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(os.getcwd(),'notebook', 'fruits-360')\n",
    "dataset_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Test')\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), \n",
    "])\n",
    "\n",
    "dataset = ImageFolder(dataset_dir, transform=transform)\n",
    "test = ImageFolder(test_dir, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fb6f7226370>"
      ]
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "# Fixed rand. seed for reproducibility of results\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training data:   872 entries\nValidation data: 46 entries\nTest data:       309 entries\n"
     ]
    }
   ],
   "source": [
    "train_size = int(0.95 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "train, val = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('Training data:   {} entries'.format(len(train)))\n",
    "print('Validation data: {} entries'.format(len(val)))\n",
    "print('Test data:       {} entries'.format(len(test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def show_example(img, label):\n",
    "#     print('Label: ', dataset.classes[label], \"(\"+str(label)+\")\")\n",
    "#     plt.imshow(img.permute(1, 2, 0))\n",
    "\n",
    "# show_example(*dataset[500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparams\n",
    "lr = 0.001\n",
    "batch_size = 128\n",
    "num_classes = len(dataset.classes)\n",
    "num_epochs = 2\n",
    "input_size = np.prod(dataset[0][0].shape)  # collapse all dimensions to calculate raw size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(dataset=val, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(dataset=test, batch_size=batch_size*4, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.utils import make_grid\n",
    "\n",
    "# def show_batch(dl):\n",
    "#     for images, labels in dl:\n",
    "#         fig, ax = plt.subplots(figsize=(12, 6))\n",
    "#         ax.set_xticks([]); ax.set_yticks([])\n",
    "#         ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n",
    "#         break\n",
    "# show_batch(train_loader)"
   ]
  },
  {
   "source": [
    "## 1. Feedforward Neural Network"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check training accuracy\n",
    "def check_accuracy(loader, model):\n",
    "    num_correct = 0\n",
    "    num_samples = 0    \n",
    "    model.eval()  # turn on evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device)\n",
    "            y = y.to(device=device)\n",
    "            x = x.reshape(x.shape[0], -1)\n",
    "\n",
    "            scores = model(x)\n",
    "            _, predictions = scores.max(1)\n",
    "            num_correct += (predictions == y).sum()\n",
    "            num_samples += predictions.size(0)\n",
    "        print(f\"Accuracy {float(num_correct) / float(num_samples) * 100:.2f}%\")\n",
    "    \n",
    "    model.train()  # go back to training mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspired by: https://github.com/aladdinpersson/Machine-Learning-Collection/blob/4bd862577ae445852da1c1603ade344d3eb03679/ML/Pytorch/Basics/pytorch_simple_fullynet.py\n",
    "imsize = 100\n",
    "# loader = transforms.Compose([transforms.ToTensor(), transforms.Scale((imsize, imsize)), transforms.ToTensor()])\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(NN, self).__init__()\n",
    "        self.linear_1 = nn.Linear(input_size, 128)\n",
    "        self.linear_2 = nn.Linear(128, 64)\n",
    "        self.linear_3 = nn.Linear(64, 32)\n",
    "        self.linear_4 = nn.Linear(32, output_size)\n",
    "\n",
    "    def forward(self, x):        \n",
    "        x = x.view(x.size(0), -1)\n",
    "        out = self.linear_1(x)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear_2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear_3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear_4(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise feedforward model\n",
    "model = NN(input_size=input_size, output_size=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1\n",
      "\tBatch 1\n",
      "\tBatch 2\n",
      "\tBatch 3\n",
      "\tBatch 4\n",
      "\tBatch 5\n",
      "\tBatch 6\n",
      "\tBatch 7\n",
      "Accuracy 100.00%\n",
      "Accuracy 100.00%\n",
      "Epoch 2\n",
      "\tBatch 1\n",
      "\tBatch 2\n",
      "\tBatch 3\n",
      "\tBatch 4\n",
      "\tBatch 5\n",
      "\tBatch 6\n",
      "\tBatch 7\n",
      "Accuracy 100.00%\n",
      "Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "# train network\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'Epoch {epoch+1}')\n",
    "    for batch_idx, (data, targets) in enumerate(train_loader):\n",
    "        print(f'\\tBatch {batch_idx+1}')\n",
    "        # use CUDA if possible\n",
    "        data = data.to(device=device)\n",
    "        targets = targets.to(device=device)\n",
    "\n",
    "        data = data.reshape(data.shape[0], -1)\n",
    "\n",
    "        # forward\n",
    "        scores = model(data)\n",
    "        loss = loss_fn(scores, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    check_accuracy(train_loader, model)\n",
    "    check_accuracy(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(train_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(val_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 100.00%\n"
     ]
    }
   ],
   "source": [
    "check_accuracy(test_loader, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(model, 'avocado_classifier.pth')\n",
    "# model = torch.load('avocado_classifier.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: tymokvo's reply @https://discuss.pytorch.org/t/how-to-classify-single-image-using-loaded-net/1411\n",
    "\n",
    "from PIL import Image\n",
    "from torch.autograd import Variable\n",
    "\n",
    "imsize = 100\n",
    "loader = transforms.Compose([transforms.Resize((imsize, imsize)), transforms.ToTensor()])\n",
    "\n",
    "def image_loader(image_path):\n",
    "    \"\"\"load image, returns cuda tensor\"\"\"\n",
    "    img = Image.open(image_path)\n",
    "    img = loader(img).float()\n",
    "    img = img.unsqueeze(0)  #this is for VGG, may not be needed for ResNet\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful discussion: https://discuss.pytorch.org/t/how-can-my-net-produce-negative-outputs-when-i-use-relu/19483/3\n",
    "image = image_loader('avocado_1.jpg')\n",
    "plt.imshow(transforms.ToPILImage()(image.squeeze(0)))\n",
    "p_1 = F.softmax(model.forward(image))\n",
    "p_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = image_loader('avocado_9.jpg')\n",
    "plt.imshow(transforms.ToPILImage()(image.squeeze(0)))\n",
    "p_2 = F.softmax(model.forward(image))\n",
    "p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p, idx = p_2.max(1)\n",
    "dataset.classes[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ripeness = 'ripe' if (idx == 1).all() else 'unripe'\n",
    "print('The avocado is {} with a {:.2f}% probability'.format(ripeness, p[0]*100))\n"
   ]
  }
 ]
}